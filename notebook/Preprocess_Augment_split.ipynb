{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocess-Augment-split.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l41xaAN7-d9H",
        "outputId": "e52f655a-19d8-4679-fe06-0355877f1537"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc0Y4p1djQCV"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2jGqXvOjC-r"
      },
      "source": [
        "import os\n",
        "import glob \n",
        "import keras\n",
        "import shutil\n",
        "import random \n",
        "import imageio \n",
        "import skimage \n",
        "import tensorflow \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from skimage import io \n",
        "from skimage import data\n",
        "from numpy import expand_dims\n",
        "import matplotlib.pyplot as plt  \n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klwVUAYQjD18"
      },
      "source": [
        "# Preprocessing and Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPm5CuwWg0eC"
      },
      "source": [
        "counter = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5RfTVjLjG-6"
      },
      "source": [
        "# Importing and Loading the data into a data frame\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/Farsi-Digit-Detection/custom-datasets/DS2/valid/images'\n",
        "\n",
        "# apply glob module to retrieve files/pathnames  \n",
        "\n",
        "digit_path = os.path.join(dataset_path, '*')\n",
        "digit_path = glob.glob(digit_path)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGuqwWQAkkq_",
        "outputId": "adf2230b-089a-45b2-f676-a1e57f38d042"
      },
      "source": [
        "len(digit_path) #30+240+29"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MdvaSGx1VI1"
      },
      "source": [
        "## Resizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_pHXNy-1Uur"
      },
      "source": [
        "def resize(image):\n",
        "\n",
        "  global counter\n",
        "\n",
        "  #Read image\n",
        "  image = Image.open(image)\n",
        "\n",
        "  #Resize image\n",
        "  image = image.resize((416,416),Image.ANTIALIAS)\n",
        "  path = \"/content/drive/MyDrive/Farsi-Digit-Detection/images/\" + str(counter) + \".jpeg\"\n",
        "  counter = counter + 1\n",
        "\n",
        "  #Save image\n",
        "  image.save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEjn88SRmKcV"
      },
      "source": [
        "## Grayscale conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBQfuDUyl66e"
      },
      "source": [
        "def gary_scale(image):\n",
        "  gray_image = skimage.color.rgb2gray(image)\n",
        "\n",
        "  return gray_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg6p3wTU7x-E"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "driSB09wmC36"
      },
      "source": [
        "def normalization(image):\n",
        "  norm_image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "  \n",
        "  return norm_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQroScV_8V4x"
      },
      "source": [
        "## Flipping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhCwop9373Oo"
      },
      "source": [
        "def flipping(image):\n",
        "\n",
        "  global counter\n",
        "\n",
        "  # convert to numpy array\n",
        "  data = img_to_array(image)\n",
        "\n",
        "  # expand dimension to one sample\n",
        "  samples = expand_dims(image, 0)\n",
        "\n",
        "  # ImageDataGenerator for flipping\n",
        "  datagen = ImageDataGenerator(horizontal_flip=True, vertical_flip=True)\n",
        "\n",
        "  # create an iterator\n",
        "  it = datagen.flow(samples, batch_size=1)\n",
        "\n",
        "  # generate batch of images\n",
        "  for i in range(3):\n",
        "\n",
        "    # convert to unsigned integers\n",
        "    image = next(it)[0].astype('uint8')\n",
        "\n",
        "    #save generated images\n",
        "    filename = \"/content/drive/MyDrive/Farsi-Digit-Detection/custom-dataset/flipped-images/\" + str(counter) + \".jpeg\"\n",
        "    counter = counter + 1\n",
        "    imageio.imwrite(filename, image)\n",
        "      \n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuUsgdNy8y94"
      },
      "source": [
        "## Rotation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfBLVe5b8nsH"
      },
      "source": [
        "def rotation(image):\n",
        "\n",
        "  global counter\n",
        "\n",
        "  # convert to numpy array\n",
        "  data = img_to_array(image)\n",
        "\n",
        "  # expand dimension to one sample\n",
        "  samples = expand_dims(image, 0)\n",
        "\n",
        "  # create an iterator\n",
        "  datagen = ImageDataGenerator(rotation_range=20, fill_mode='nearest')\n",
        "\n",
        "  # create an iterator\n",
        "  it = datagen.flow(samples, batch_size=1)\n",
        "\n",
        "  # generate batch of images\n",
        "  for i in range(3):\n",
        "\n",
        "    # convert to unsigned integers\n",
        "    image = next(it)[0].astype('uint8')\n",
        "\n",
        "    #save generated images\n",
        "    filename = \"/content/drive/MyDrive/Farsi-Digit-Detection/custom-dataset/pelak-dataset/rotated-images/\" + str(counter) + \".jpeg\"\n",
        "    counter = counter + 1\n",
        "    imageio.imwrite(filename, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSvtDG-353BQ"
      },
      "source": [
        "## Calling Resize Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hS7bBag52he"
      },
      "source": [
        "for i in range(0,len(digit_path)):\n",
        "  #image = io.imread(digit_path[i])\n",
        "  resize(digit_path[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiAEiVjyTtMW"
      },
      "source": [
        "## Calling Augmentation Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LySHsN2l9ISX",
        "outputId": "a99ce29b-02a3-40a1-ea68-02f80bce63e1"
      },
      "source": [
        "for i in range(0,len(digit_path)): \n",
        "  image = io.imread(digit_path[i])\n",
        "  try:\n",
        "    #flipping(image)\n",
        "    rotation(image)\n",
        "  except:\n",
        "    print(digit_path[i])\n",
        "\n",
        "print(\"END\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "END\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6HZuQUxqmhS"
      },
      "source": [
        "## Calling Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoRsFLajYrrY"
      },
      "source": [
        "for i in range(0,len(digit_path)): \n",
        "  image = io.imread(digit_path[i])\n",
        "  gray_image = gary_scale(image)\n",
        "  norm_image = normalization(image)\n",
        "  path = \"/content/drive/MyDrive/Farsi-Digit-Detection/normalized-images/\" + str(i) + \".jpeg\"\n",
        "  imageio.imwrite(path, norm_image)\n",
        "print(\"END\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrCbn2b4FCTE"
      },
      "source": [
        "# Spiliting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRzombpuFIIY"
      },
      "source": [
        "current_dir = \"/content/drive/MyDrive/Farsi-Digit-Detection/Hoda-Dataset/images\"\n",
        "# Percentage of images to be used for the valid set\n",
        "percentage_test = 20\n",
        "\n",
        "flag = True\n",
        "\n",
        "# Create train.txt and valid.txt\n",
        "file_train = \"/content/drive/MyDrive/Farsi-Digit-Detection/Hoda-Dataset/train\" \n",
        "file_test = \"/content/drive/MyDrive/Farsi-Digit-Detection/Hoda-Dataset/test\"\n",
        "file_valid = \"/content/drive/MyDrive/Farsi-Digit-Detection/Hoda-Dataset/valid\"\n",
        "# Populate train.txt and valid.txt\n",
        "counter = 1  \n",
        "index_test = round(100 / percentage_test)  \n",
        "for file in glob.iglob(os.path.join(current_dir, '*.png')):  \n",
        "    title, ext = os.path.splitext(os.path.basename(file))\n",
        "    cur_img = current_dir + \"/\" + title + '.png'\n",
        "    cur_lbl = \"/content/drive/MyDrive/Farsi-Digit-Detection/Hoda-Dataset/labels/\"  + title + '.txt'\n",
        "\n",
        "    if counter == index_test:\n",
        "      if flag == True :\n",
        "        test_img = file_test + '/images'  \n",
        "        test_lbl = file_test + '/labels'  \n",
        "        shutil.move(cur_img,test_img)\n",
        "        shutil.move(cur_lbl,test_lbl)\n",
        "      else:\n",
        "        valid_img = file_valid + '/images'  \n",
        "        valid_lbl = file_valid + '/labels'  \n",
        "        shutil.move(cur_img,valid_img)\n",
        "        shutil.move(cur_lbl,valid_lbl)\n",
        "      flag = not flag\n",
        "      counter = 1\n",
        "    else:\n",
        "        train_img = file_train + '/images'  \n",
        "        train_lbl = file_train + '/labels'  \n",
        "        shutil.move(cur_img,train_img)\n",
        "        shutil.move(cur_lbl,train_lbl)\n",
        "        counter = counter + 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}